{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9902420-c692-4b92-8f14-cc9e38f5ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial import distance\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import math\n",
    "import copy\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.linear_model import Lasso\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066e083a-5463-48c4-85ff-9f72c3f34c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [3.0143364  4.21106128 4.49056789 6.84433191 4.38055757 4.59035439\n",
      " 5.62650526 4.348927   3.26627828 2.23006741]\n"
     ]
    }
   ],
   "source": [
    "with open('relation_matrix_dic.pkl', 'rb') as f:\n",
    "    relation_matrix_dic = pickle.load(f)\n",
    "\n",
    "# define a new adjacency_matrix_dic: adjacency_matrix_dic[i] = relation_matrix_dic[i].iloc[0:20, 0:20]\n",
    "adjacency_matrix_dic = {i: relation_matrix_dic[i].iloc[0:20, 0:20] for i in relation_matrix_dic}\n",
    "\n",
    "# Copy adjacency_matrix_dic and extend its keys\n",
    "adjacency_matrix_dic_new = adjacency_matrix_dic.copy()\n",
    "\n",
    "for i in range(100):\n",
    "    adjacency_matrix_dic_new[i + 100] = adjacency_matrix_dic[i]\n",
    "\n",
    "# Update the original adjacency_matrix_dic with the extended dictionary\n",
    "adjacency_matrix_dic = adjacency_matrix_dic_new\n",
    "\n",
    "# Read beta back from the file\n",
    "beta = np.load('beta.npy')\n",
    "print(\"beta:\", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d332fd2c-fa0a-423e-85b3-3696d82b78e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjacency_matrix_dic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf4173d-6c1e-48b5-8a95-c4c812402b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# follow the beta, only 1,2,3 related is non-zero\n",
    "K = 14\n",
    "\n",
    "# Compute total length\n",
    "total_length = 1 + K + K + math.comb(K, 2)\n",
    "total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122ff145-5cc5-4027-884e-8ca6906e5242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_beta: [3.0143364  4.21106128 4.49056789 6.84433191 0.         0.\n",
      " 0.         0.         0.         0.         4.38055757 4.59035439\n",
      " 5.62650526 0.         0.         0.         0.         0.\n",
      " 0.         0.         4.348927   3.26627828 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "new_beta = np.zeros(total_length)\n",
    "\n",
    "# Assign values based on the provided instructions\n",
    "new_beta[0:4] = beta[0:4]            # Copy the first four elements unchanged\n",
    "new_beta[10:13] = beta[4:7]          # Copy beta[4:6] into new_beta[11:13]\n",
    "new_beta[20:22] = beta[7:9]          # Copy beta[7:8] into new_beta[20:21]\n",
    "\n",
    "# Print the new_beta array\n",
    "print(\"new_beta:\", new_beta)\n",
    "\n",
    "beta = new_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246a72a4-4af8-400a-8999-31402191f36e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0: beta = 3.0143363957683738\n",
      "Position 1: beta = 4.211061281023643\n",
      "Position 2: beta = 4.490567890019025\n",
      "Position 3: beta = 6.84433191283132\n",
      "Position 4: beta = 0.0\n",
      "Position 5: beta = 0.0\n",
      "Position 6: beta = 0.0\n",
      "Position 7: beta = 0.0\n",
      "Position 8: beta = 0.0\n",
      "Position 9: beta = 0.0\n",
      "Position (1,1): beta = 4.3805575746037055\n",
      "Position (1,2): beta = 4.590354387978943\n",
      "Position (1,3): beta = 5.626505257258666\n",
      "Position (1,4): beta = 0.0\n",
      "Position (1,5): beta = 0.0\n",
      "Position (1,6): beta = 0.0\n",
      "Position (1,7): beta = 0.0\n",
      "Position (1,8): beta = 0.0\n",
      "Position (1,9): beta = 0.0\n",
      "Position (2,2): beta = 0.0\n",
      "Position (2,3): beta = 4.348926998816991\n",
      "Position (2,4): beta = 3.2662782844053506\n",
      "Position (2,5): beta = 0.0\n",
      "Position (2,6): beta = 0.0\n",
      "Position (2,7): beta = 0.0\n",
      "Position (2,8): beta = 0.0\n",
      "Position (2,9): beta = 0.0\n",
      "Position (3,3): beta = 0.0\n",
      "Position (3,4): beta = 0.0\n",
      "Position (3,5): beta = 0.0\n",
      "Position (3,6): beta = 0.0\n",
      "Position (3,7): beta = 0.0\n",
      "Position (3,8): beta = 0.0\n",
      "Position (3,9): beta = 0.0\n",
      "Position (4,4): beta = 0.0\n",
      "Position (4,5): beta = 0.0\n",
      "Position (4,6): beta = 0.0\n",
      "Position (4,7): beta = 0.0\n",
      "Position (4,8): beta = 0.0\n",
      "Position (4,9): beta = 0.0\n",
      "Position (5,5): beta = 0.0\n",
      "Position (5,6): beta = 0.0\n",
      "Position (5,7): beta = 0.0\n",
      "Position (5,8): beta = 0.0\n",
      "Position (5,9): beta = 0.0\n",
      "Position (6,6): beta = 0.0\n",
      "Position (6,7): beta = 0.0\n",
      "Position (6,8): beta = 0.0\n",
      "Position (6,9): beta = 0.0\n",
      "Position (7,7): beta = 0.0\n",
      "Position (7,8): beta = 0.0\n",
      "Position (7,9): beta = 0.0\n",
      "Position (8,8): beta = 0.0\n",
      "Position (8,9): beta = 0.0\n",
      "Position (9,9): beta = 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Position {i}: beta = {beta[i]}\")\n",
    "\n",
    "idx = 10\n",
    "\n",
    "for i in range(1, 10):\n",
    "    for j in range(1, 10):\n",
    "        if i <= j:\n",
    "            print(f\"Position ({i},{j}): beta = {beta[idx]}\")\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e845e5-ddca-4ecc-b0c2-d73301f07fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function named \"counting_treatment\"\n",
    "def counting_treatment(adjacency_matrix, A, K):\n",
    "\n",
    "    # adjacency_matrix is a adjacency matrix dataframe with length 20 * 20 known\n",
    "    # A is a np.array with length 20, each element 1,2,...,K known corresponding to each node in the network\n",
    "\n",
    "    # a empty df named counting_treatment with column named: 0,1,...,K, (1,1), ..., (1,K), (2,2), ..., (2,K),...(K,K)\n",
    "\n",
    "    # add different numbers of different nodes and different edges. For the column 0, directly give 1.\n",
    "\n",
    "    # Define column names\n",
    "    basic_columns = list(range(0, K + 1))  # Including column 0\n",
    "    edge_columns = [(i, j) for i in range(1, K + 1) for j in range(i, K + 1)]\n",
    "    columns = basic_columns + edge_columns\n",
    "    \n",
    "    # Create an empty DataFrame\n",
    "    counting_treatment_df = pd.DataFrame(columns=columns)\n",
    "    counting_treatment_df.loc[0] = 0  # Initialize all counts to 0\n",
    "    \n",
    "    # Column 0 gets the value of 1 as per the description\n",
    "    counting_treatment_df.at[0, 0] = 1\n",
    "\n",
    "    # Count number of nodes with each treatment\n",
    "    for treatment in range(1, K + 1):\n",
    "        counting_treatment_df.at[0, treatment] = sum(A == treatment)\n",
    "    \n",
    "    # Count the number of edges connecting nodes of different treatments\n",
    "    for i in range(len(adjacency_matrix_dic[0])):\n",
    "        for j in range(i + 1, len(adjacency_matrix_dic[0])):  # Iterate only for j > i to avoid double-counting\n",
    "            if adjacency_matrix.iloc[i, j] != 0:  # If there's an edge between node i and node j\n",
    "                treatment_i = A[i]\n",
    "                treatment_j = A[j]\n",
    "                # Use sorted tuple to represent undirected edge\n",
    "                edge = tuple(sorted((treatment_i, treatment_j)))\n",
    "                if edge in counting_treatment_df.columns:\n",
    "                    counting_treatment_df.at[0, edge] += 1\n",
    "                \n",
    "    return counting_treatment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820eed2-924b-499f-9091-60571f5e32bf",
   "metadata": {},
   "source": [
    "# generate_outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095cf8e3-4b66-4d19-8554-349b2635b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outcome(adjacency_matrix, A, K, beta, error):\n",
    "    # Generate the treatment matrix using the counting_treatment function\n",
    "    counting_treatment_df = counting_treatment(adjacency_matrix, A, K)\n",
    "\n",
    "    # Convert the treatment matrix to a NumPy array for easier calculation\n",
    "    counting_treatment_array = counting_treatment_df.values.flatten()\n",
    "\n",
    "    # Ensure that beta and counting_treatment_array have the same length\n",
    "    if len(beta) != len(counting_treatment_array):\n",
    "        raise ValueError(\"Length of beta does not match the number of columns in counting_treatment.\")\n",
    "\n",
    "    # Compute the outcome Y\n",
    "    Y_exp = np.dot(counting_treatment_array, beta)\n",
    "    \n",
    "    Y = np.dot(counting_treatment_array, beta) + error\n",
    "\n",
    "    # Return the results\n",
    "    return Y, Y_exp, counting_treatment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa410b-ce4e-44a5-9392-2d3ef9552ad7",
   "metadata": {},
   "source": [
    "# lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa8d339e-f80c-4d8f-a141-553d0b6d850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lasso_model(experimented_data, lambda_value):\n",
    "    # Step 1: Prepare Data (X, Y)\n",
    "    # X consists of all data except 'Y' from experimented_data\n",
    "    X = experimented_data.iloc[:, :-1].values  # Take all columns except the last one (assumed 'Y' is the last column)\n",
    "    Y = experimented_data['Y'].values.reshape(-1, 1)  # Rewards (Y) as a column vector\n",
    "    \n",
    "    # Step 2: Fit Lasso Regression Model with lambda (alpha) as the regularization parameter\n",
    "    lasso_model = Lasso(alpha=lambda_value)  # Lambda corresponds to the alpha parameter in Lasso\n",
    "    \n",
    "    # Train the Lasso model\n",
    "    lasso_model.fit(X, Y.ravel())  # Use ravel to convert Y to a 1D array\n",
    "    \n",
    "    return lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aae4aad6-0638-4e6a-93df-63906bd992df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lasso_reward(A, model, adjacency_matrix, K):\n",
    "\n",
    "    # Predict for new target treatments\n",
    "    # Generate new target treatments using counting_treatment function\n",
    "    counting_treatment_df = counting_treatment(adjacency_matrix, A, K)  # Get DataFrame representation\n",
    "    \n",
    "    # Convert the dataframe to a NumPy array for GPy compatibility\n",
    "    X_target = counting_treatment_df.values  # Convert the DataFrame to a NumPy array\n",
    "\n",
    "    if X_target.ndim == 1:\n",
    "        X_target = X_target.reshape(1, -1)  # Reshape to be a 2D array with one row\n",
    "\n",
    "    # Predict the rewards and the full covariance matrix for the new target treatments\n",
    "    predicted_reward = model.predict(X_target)\n",
    "\n",
    "    # Simplify the results to a scalar value if necessary\n",
    "    # For Lasso, the output of .predict() should be a 1D array, so we can just return the first value\n",
    "    \n",
    "    return predicted_reward[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22a4d16f-449a-4a30-b7ab-e6f0f60179e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization genetic algorithm\n",
    "def get_children_elite(parent_treatment_dic, parent_reward_predict, model, adjacency_matrix, K, generation_num):\n",
    "    child_treatment_dic = {}\n",
    "    child_reward_predict = {}\n",
    "    \n",
    "    # Step 2: Generate children from parent treatments using roulette wheel selection\n",
    "    for i in range(generation_num):\n",
    "        # Use roulette wheel selection to choose two parents based on UCB values\n",
    "        A1, A2 = roulette_wheel_selection(parent_reward_predict, parent_treatment_dic)\n",
    "        \n",
    "        # Crossover: with 0.5 probability choose genes from A1 or A2\n",
    "        child_treatment_dic[i + generation_num] = np.where(np.random.rand(len(A1)) < 0.5, A1, A2)\n",
    "        \n",
    "        # Predict reward and UCB for the new child\n",
    "        predicted_rewards = predict_lasso_reward(child_treatment_dic[i + generation_num], model, adjacency_matrix, K)\n",
    "        child_reward_predict[i + generation_num] = predicted_rewards\n",
    "\n",
    "    # Step 3: Select the top treatments from both parents and children\n",
    "    combined_predict = {**parent_reward_predict, **child_reward_predict}\n",
    "    \n",
    "    # Sort the combined dictionary by UCB values and select the top N treatments\n",
    "    sorted_indices = sorted(combined_predict, key=combined_predict.get, reverse=True)[:generation_num]\n",
    "    child_elite = {idx: combined_predict[idx] for idx in sorted_indices}\n",
    "    \n",
    "    child_elite_treatment_dic = {}\n",
    "    for idx in sorted_indices:\n",
    "        if idx in parent_reward_predict:\n",
    "            child_elite_treatment_dic[idx] = parent_treatment_dic[idx]\n",
    "        else:\n",
    "            child_elite_treatment_dic[idx] = child_treatment_dic[idx]\n",
    "\n",
    "    return child_elite_treatment_dic, child_elite\n",
    "\n",
    "\n",
    "def roulette_wheel_selection(reward_predict, treatment_dic):\n",
    "\n",
    "    values = np.array(list(reward_predict.values()))\n",
    "\n",
    "    # Ensure no negative values by shifting if necessary\n",
    "    if np.min(values) < 0:\n",
    "        values = values - np.min(values)  # Shift values to make them non-negative\n",
    "    \n",
    "    total = np.sum(values)\n",
    "    \n",
    "    if total > 0:\n",
    "        probabilities = values / total  # Normalize to create valid probabilities\n",
    "    else:\n",
    "        # If all UCB values are zero, use uniform probability\n",
    "        probabilities = np.ones_like(values) / len(values)  # Equal probability if all UCB are zero\n",
    "\n",
    "    # Select two parents based on the computed probabilities\n",
    "    selected_indices = np.random.choice(len(values), size=2, p=probabilities, replace=False)\n",
    "    return treatment_dic[selected_indices[0]], treatment_dic[selected_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dde1c17-7766-411a-9de3-e193e878cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the next experiment\n",
    "\n",
    "def get_next_experiment(model, adjacency_matrix, K, generation_num, epoch):\n",
    "    parent_treatment_dic = {i: np.random.randint(1, K+1, size=adjacency_matrix.shape[0]) for i in range(100)}\n",
    "    parent_reward_predict = {}\n",
    "    \n",
    "    # Step 1: Calculate UCB for parent treatments\n",
    "    for i in range(generation_num):\n",
    "        predicted_rewards = predict_lasso_reward(parent_treatment_dic[i], model, adjacency_matrix, K)\n",
    "        # UCB\n",
    "        parent_reward_predict[i] = predicted_rewards\n",
    "\n",
    "        \n",
    "    # Epoch loop\n",
    "    # Initialize variables\n",
    "    no_progress_counter = 0  # Counter to track epochs without improvement\n",
    "    best = -np.inf  # To store the best UCB value so far\n",
    "    \n",
    "    \n",
    "    # Epoch loop\n",
    "    for k in range(1, epoch + 1):\n",
    "        # Get the elite children treatments and UCBs\n",
    "        child_elite_treatment_dic, child_elite = get_children_elite(parent_treatment_dic, parent_reward_predict, model, adjacency_matrix, K, generation_num)\n",
    "        \n",
    "        # Reassign parent treatments and UCB predictions with renumbered indices\n",
    "        parent_treatment_dic = {new_idx: treatment for new_idx, treatment in enumerate(child_elite_treatment_dic.values())}\n",
    "        parent_reward_predict = {new_idx: sur for new_idx, sur in enumerate(child_elite.values())}\n",
    "    \n",
    "        # Get the best UCB in this epoch\n",
    "        current_best = parent_reward_predict[0]\n",
    "    \n",
    "        # Print the UCB of the best treatment after each epoch\n",
    "        # print(f\"Epoch {k}: Best UCB = {current_best}\")\n",
    "    \n",
    "        # Check if the best UCB has improved\n",
    "        if current_best > best:\n",
    "            best = current_best  # Update the best UCB\n",
    "            no_progress_counter = 0  # Reset the counter\n",
    "        else:\n",
    "            no_progress_counter += 1  # No improvement, increment the counter\n",
    "    \n",
    "        # If no improvement for 10 epochs, break the loop\n",
    "        if no_progress_counter >= 10:\n",
    "            # print(f\"No improvement for 10 consecutive epochs. Stopping at epoch {k}.\")\n",
    "            break\n",
    "\n",
    "    return parent_treatment_dic[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4aef02-bccc-4efc-9e9e-fda44d9f3dad",
   "metadata": {},
   "source": [
    "# initial experiment 0: for a selected vector treatments, we get rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e66a9645-0133-43bc-9c3b-1516eee3c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration_then_exploitation(E):\n",
    "\n",
    "    d = len(beta)\n",
    "    sigma = 1\n",
    "    lambda_value = 2 * sigma\n",
    "\n",
    "    # Initialize empty lists to store A and reward over time\n",
    "    A_time = []\n",
    "    reward_time = []\n",
    "    \n",
    "    # Create an empty DataFrame for experimented data\n",
    "    experimented_data = pd.DataFrame()\n",
    "\n",
    "    # Get the length of adjacency_matrix_dic (number of keys)\n",
    "    length = len(adjacency_matrix_dic)\n",
    "    \n",
    "    # Generate the error array from a normal distribution with the specified length\n",
    "    mean = 0  # Define the mean\n",
    "    std_dev = sigma\n",
    "    \n",
    "    error_array = mean + std_dev * np.random.randn(length)\n",
    "    \n",
    "    for t in range(E):\n",
    "        # Create an array A , with length matching the adjacency matrix\n",
    "        A = np.random.randint(1, K + 1, size=adjacency_matrix_dic[t].shape[0])\n",
    "\n",
    "        Y, Y_exp, counting_treatment_df = generate_outcome(adjacency_matrix_dic[t], A, K, beta, error_array[t])\n",
    "        \n",
    "        # Create a DataFrame for Y\n",
    "        Y_df = pd.DataFrame([Y], columns=['Y'])\n",
    "        \n",
    "        # Concatenate treatment and Y_df to form experimented_data (append vertically)\n",
    "        experiment_data_current = pd.concat([counting_treatment_df, Y_df], axis=1)\n",
    "        \n",
    "        # Append to the existing DataFrame (vertically concatenating)\n",
    "        experimented_data = pd.concat([experimented_data, experiment_data_current], axis=0, ignore_index=True)\n",
    "        \n",
    "        # Append A and total reward to the respective lists\n",
    "        reward_time.append(Y_exp)\n",
    "\n",
    "    generation_num = 100\n",
    "    epoch = 100\n",
    "\n",
    "    T = 200\n",
    "\n",
    "    model = predict_lasso_model(experimented_data, lambda_value)\n",
    "        \n",
    "    # Get the next treatment vector A\n",
    "    A = get_next_experiment(model, adjacency_matrix_dic[t], K, generation_num, epoch)\n",
    "    \n",
    "    # Generate the outcome based on A\n",
    "    Y, Y_exp, counting_treatment_df = generate_outcome(adjacency_matrix_dic[t], A, K, beta, error_array[t])\n",
    "\n",
    "    for t in range(E,T):  # Iterate for T time steps\n",
    "\n",
    "        # Get the next treatment vector A\n",
    "        A = get_next_experiment(model, adjacency_matrix_dic[t], K, generation_num, epoch)\n",
    "        \n",
    "        # Generate the outcome based on A\n",
    "        Y, Y_exp, counting_treatment_df = generate_outcome(adjacency_matrix_dic[t], A, K, beta, error_array[t])\n",
    "\n",
    "        \n",
    "        reward_time.append(Y_exp)\n",
    "    \n",
    "        # Print the reward for the current time step\n",
    "        print(f\"Time {t} with reward: {Y_exp}\")\n",
    "        # print(f\"Time {t} with treatment: {A}\")\n",
    "\n",
    "    # Convert reward_time to a NumPy array\n",
    "    reward_time = np.array(reward_time)\n",
    "\n",
    "    return reward_time\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e4c1105-8d1f-4961-b153-20838e3bdcb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment 1 for ete\n",
      "Time 130 with reward: 358.1098274030349\n",
      "Time 131 with reward: 346.86152688879577\n",
      "Time 132 with reward: 314.12603585396755\n",
      "Time 133 with reward: 301.43591070062064\n",
      "Time 134 with reward: 330.0071658402734\n",
      "Time 135 with reward: 257.8637714181686\n",
      "Time 136 with reward: 349.5865034055351\n",
      "Time 137 with reward: 279.0405562866745\n",
      "Time 138 with reward: 298.6382259931066\n",
      "Time 139 with reward: 295.23408199090784\n",
      "Time 140 with reward: 281.20585371549777\n",
      "Time 141 with reward: 264.98445514049354\n",
      "Time 142 with reward: 338.7050198379074\n",
      "Time 143 with reward: 296.29839856414907\n",
      "Time 144 with reward: 313.73077084175793\n",
      "Time 145 with reward: 234.66149972539756\n",
      "Time 146 with reward: 286.07981774353584\n",
      "Time 147 with reward: 330.33996110209677\n",
      "Time 148 with reward: 253.92844157273166\n",
      "Time 149 with reward: 304.2280669680244\n",
      "Time 150 with reward: 289.92203985430217\n",
      "Time 151 with reward: 301.29804498282726\n",
      "Time 152 with reward: 345.0630464065839\n",
      "Time 153 with reward: 316.9603848438224\n",
      "Time 154 with reward: 335.43874155350204\n",
      "Time 155 with reward: 314.95128527396287\n",
      "Time 156 with reward: 351.6872636812467\n",
      "Time 157 with reward: 279.9670071421223\n",
      "Time 158 with reward: 273.76455805850264\n",
      "Time 159 with reward: 377.86369496843076\n",
      "Time 160 with reward: 342.91608111893106\n",
      "Time 161 with reward: 371.2944741172792\n",
      "Time 162 with reward: 284.60999771769644\n",
      "Time 163 with reward: 259.77568184206575\n",
      "Time 164 with reward: 306.0789012761947\n",
      "Time 165 with reward: 350.6691521199467\n",
      "Time 166 with reward: 301.5459035476432\n",
      "Time 167 with reward: 336.0894609733632\n",
      "Time 168 with reward: 337.6040389823253\n",
      "Time 169 with reward: 388.643977100606\n",
      "Time 170 with reward: 309.65695490462065\n",
      "Time 171 with reward: 362.5966201196452\n",
      "Time 172 with reward: 427.8305251019001\n",
      "Time 173 with reward: 318.9049472605703\n",
      "Time 174 with reward: 322.4102926982215\n",
      "Time 175 with reward: 343.10894326023566\n",
      "Time 176 with reward: 350.724148543458\n",
      "Time 177 with reward: 363.853798834191\n",
      "Time 178 with reward: 347.3016724000888\n",
      "Time 179 with reward: 350.7058164022876\n",
      "Time 180 with reward: 331.6026682567529\n",
      "Time 181 with reward: 258.2223721480374\n",
      "Time 182 with reward: 263.96634357919356\n",
      "Time 183 with reward: 279.9670071421223\n",
      "Time 184 with reward: 283.6394092530328\n",
      "Time 185 with reward: 288.9949686249474\n",
      "Time 186 with reward: 297.5576446814203\n",
      "Time 187 with reward: 335.6132715536362\n",
      "Time 188 with reward: 314.9329531327925\n",
      "Time 189 with reward: 308.2625308461884\n",
      "Time 190 with reward: 325.5387052648335\n",
      "Time 191 with reward: 291.9861358476729\n",
      "Time 192 with reward: 280.14153714225654\n",
      "Time 193 with reward: 307.3360799907406\n",
      "Time 194 with reward: 353.6230346864245\n",
      "Time 195 with reward: 294.29136639701494\n",
      "Time 196 with reward: 352.81611740759956\n",
      "Time 197 with reward: 274.5392066023024\n",
      "Time 198 with reward: 328.080935564696\n",
      "Time 199 with reward: 331.0436095427438\n",
      "Running experiment 2 for ete\n",
      "Time 130 with reward: 369.2853745474197\n",
      "Time 131 with reward: 344.6045687541204\n",
      "Time 132 with reward: 298.8772931463525\n",
      "Time 133 with reward: 289.9037077131317\n",
      "Time 134 with reward: 332.15413112792623\n",
      "Time 135 with reward: 262.60796342919525\n",
      "Time 136 with reward: 375.6434011160962\n",
      "Time 137 with reward: 286.6734733371603\n",
      "Time 138 with reward: 323.4562771302923\n",
      "Time 139 with reward: 301.43591070062064\n",
      "Time 140 with reward: 288.52699542196297\n",
      "Time 141 with reward: 301.43591070062064\n",
      "Time 142 with reward: 332.0162654101329\n",
      "Time 143 with reward: 327.5294726935226\n",
      "Time 144 with reward: 323.2172099770464\n",
      "Time 145 with reward: 252.79079643480875\n",
      "Time 146 with reward: 314.62055741486495\n",
      "Time 147 with reward: 338.8428855557007\n",
      "Time 148 with reward: 275.34234870771866\n",
      "Time 149 with reward: 270.5855271473023\n",
      "Time 150 with reward: 305.7848376994376\n",
      "Time 151 with reward: 319.1073501314753\n",
      "Time 152 with reward: 366.66981568287554\n",
      "Time 153 with reward: 312.9049010478556\n",
      "Time 154 with reward: 353.48516896863117\n",
      "Time 155 with reward: 323.18054569470564\n",
      "Time 156 with reward: 367.08341283625555\n",
      "Time 157 with reward: 283.37115114432106\n",
      "Time 158 with reward: 249.94047553969955\n",
      "Time 159 with reward: 388.88304425385184\n",
      "Time 160 with reward: 353.76090040421786\n",
      "Time 161 with reward: 373.49643582844334\n",
      "Time 162 with reward: 302.0417496213983\n",
      "Time 163 with reward: 272.4017645758571\n",
      "Time 164 with reward: 301.71164213620733\n",
      "Time 165 with reward: 362.4587544018519\n",
      "Time 166 with reward: 329.73143440468675\n",
      "Time 167 with reward: 310.7035597105984\n",
      "Time 168 with reward: 334.08036140350373\n",
      "Time 169 with reward: 382.6622630290617\n",
      "Time 170 with reward: 301.71164213620733\n",
      "Time 171 with reward: 371.1749405406563\n",
      "Time 172 with reward: 432.04158638292375\n",
      "Time 173 with reward: 332.0162654101329\n",
      "Time 174 with reward: 321.42884541926236\n",
      "Time 175 with reward: 317.8039664049882\n",
      "Time 176 with reward: 356.10072783317537\n",
      "Time 177 with reward: 391.9931246792934\n",
      "Time 178 with reward: 339.1363287585509\n",
      "Time 179 with reward: 384.2033893959368\n",
      "Time 180 with reward: 316.0289002818204\n",
      "Time 181 with reward: 259.22215156816696\n",
      "Time 182 with reward: 296.9491179840103\n",
      "Time 183 with reward: 288.3891297041696\n",
      "Time 184 with reward: 307.31774784957014\n",
      "Time 185 with reward: 284.4537998587327\n",
      "Time 186 with reward: 299.89478433374546\n",
      "Time 187 with reward: 351.88966655215177\n",
      "Time 188 with reward: 327.80520412910926\n",
      "Time 189 with reward: 277.2420306253831\n",
      "Time 190 with reward: 304.73001667671724\n",
      "Time 191 with reward: 309.18898170163635\n",
      "Time 192 with reward: 270.69114191540194\n",
      "Time 193 with reward: 304.8400547028193\n",
      "Time 194 with reward: 336.53468870252993\n",
      "Time 195 with reward: 319.1073501314753\n",
      "Time 196 with reward: 338.8605973229642\n",
      "Time 197 with reward: 256.68124578116226\n",
      "Time 198 with reward: 329.86930012248007\n",
      "Time 199 with reward: 344.92518068879053\n",
      "Running experiment 3 for ete\n",
      "Time 130 with reward: 285.7102292552483\n",
      "Time 131 with reward: 290.33426731574497\n",
      "Time 132 with reward: 239.4688591975986\n",
      "Time 133 with reward: 227.1746194303682\n",
      "Time 134 with reward: 267.23187254556865\n",
      "Time 135 with reward: 220.59792525234172\n",
      "Time 136 with reward: 313.0705106922964\n",
      "Time 137 with reward: 234.19348134333373\n",
      "Time 138 with reward: 276.16879369644846\n",
      "Time 139 with reward: 247.00119518653887\n",
      "Time 140 with reward: 237.11069962747067\n",
      "Time 141 with reward: 235.73460771020888\n",
      "Time 142 with reward: 250.23080918860336\n",
      "Time 143 with reward: 273.2971600503458\n",
      "Time 144 with reward: 278.3707554076126\n",
      "Time 145 with reward: 231.67912391424204\n",
      "Time 146 with reward: 253.20302389625158\n",
      "Time 147 with reward: 248.2033774775734\n",
      "Time 148 with reward: 225.67837356257655\n",
      "Time 149 with reward: 282.1132231117449\n",
      "Time 150 with reward: 243.4048094169425\n",
      "Time 151 with reward: 248.2033774775734\n",
      "Time 152 with reward: 270.6360165477673\n",
      "Time 153 with reward: 246.68941984251825\n",
      "Time 154 with reward: 268.4884308862076\n",
      "Time 155 with reward: 264.27736960518394\n",
      "Time 156 with reward: 270.498150829974\n",
      "Time 157 with reward: 237.79870370357963\n",
      "Time 158 with reward: 207.9431011175611\n",
      "Time 159 with reward: 314.1252865359372\n",
      "Time 160 with reward: 260.69931597675793\n",
      "Time 161 with reward: 301.9866242537637\n",
      "Time 162 with reward: 242.35820461096475\n",
      "Time 163 with reward: 213.06290148676908\n",
      "Time 164 with reward: 252.34173056782228\n",
      "Time 165 with reward: 295.6673293701535\n",
      "Time 166 with reward: 239.21208027708926\n",
      "Time 167 with reward: 274.75541712293887\n",
      "Time 168 with reward: 243.46187324317918\n",
      "Time 169 with reward: 335.76872009456974\n",
      "Time 170 with reward: 242.4783585614946\n",
      "Time 171 with reward: 294.6654825472985\n",
      "Time 172 with reward: 317.17082980826723\n",
      "Time 173 with reward: 254.16675940794724\n",
      "Time 174 with reward: 266.40600275166634\n",
      "Time 175 with reward: 285.7747664083599\n",
      "Time 176 with reward: 290.16035768951775\n",
      "Time 177 with reward: 283.5632639675954\n",
      "Time 178 with reward: 268.17665554218695\n",
      "Time 179 with reward: 293.36209882081147\n",
      "Time 180 with reward: 226.77051782750908\n",
      "Time 181 with reward: 222.4120952781712\n",
      "Time 182 with reward: 212.09094975833088\n",
      "Time 183 with reward: 232.55936975774867\n",
      "Time 184 with reward: 246.7722891368003\n",
      "Time 185 with reward: 224.118915054531\n",
      "Time 186 with reward: 252.79004711677848\n",
      "Time 187 with reward: 281.67576537708425\n",
      "Time 188 with reward: 250.57924881496484\n",
      "Time 189 with reward: 240.7804139617488\n",
      "Time 190 with reward: 255.68071704300243\n",
      "Time 191 with reward: 233.4042758317723\n",
      "Time 192 with reward: 237.8353679859205\n",
      "Time 193 with reward: 253.13031570547682\n",
      "Time 194 with reward: 270.47981868880356\n",
      "Time 195 with reward: 242.6105701988269\n",
      "Time 196 with reward: 283.7839989796708\n",
      "Time 197 with reward: 225.71503784491736\n",
      "Time 198 with reward: 285.452829960832\n",
      "Time 199 with reward: 252.4327708997675\n",
      "Running experiment 4 for ete\n",
      "Time 130 with reward: 334.03548090442024\n",
      "Time 131 with reward: 357.41228259732554\n",
      "Time 132 with reward: 307.4087881815153\n",
      "Time 133 with reward: 271.2990482389051\n",
      "Time 134 with reward: 338.897881979212\n",
      "Time 135 with reward: 274.8655389140847\n",
      "Time 136 with reward: 348.6417204089168\n",
      "Time 137 with reward: 275.9842315369303\n",
      "Time 138 with reward: 298.98666561946806\n",
      "Time 139 with reward: 315.28139275915396\n",
      "Time 140 with reward: 253.50869560533445\n",
      "Time 141 with reward: 268.9027773576179\n",
      "Time 142 with reward: 358.1098274030349\n",
      "Time 143 with reward: 302.33581319815545\n",
      "Time 144 with reward: 323.5941428480856\n",
      "Time 145 with reward: 230.97278769696263\n",
      "Time 146 with reward: 295.8215887705152\n",
      "Time 147 with reward: 295.8399209116856\n",
      "Time 148 with reward: 256.50671578102805\n",
      "Time 149 with reward: 309.6392431373572\n",
      "Time 150 with reward: 305.30802790580367\n",
      "Time 151 with reward: 285.68517310523316\n",
      "Time 152 with reward: 319.7492329606869\n",
      "Time 153 with reward: 270.69114191540194\n",
      "Time 154 with reward: 318.2358956995387\n",
      "Time 155 with reward: 299.0049977606385\n",
      "Time 156 with reward: 382.3321555438706\n",
      "Time 157 with reward: 280.5911782040705\n",
      "Time 158 with reward: 260.00190011517196\n",
      "Time 159 with reward: 408.030452524563\n",
      "Time 160 with reward: 317.87799910862077\n",
      "Time 161 with reward: 351.7701329755288\n",
      "Time 162 with reward: 275.6663073788925\n",
      "Time 163 with reward: 263.8190208968438\n",
      "Time 164 with reward: 301.39103020153715\n",
      "Time 165 with reward: 336.73196417648177\n",
      "Time 166 with reward: 297.6751108553178\n",
      "Time 167 with reward: 313.9053008418921\n",
      "Time 168 with reward: 340.57625368997356\n",
      "Time 169 with reward: 389.8644915328109\n",
      "Time 170 with reward: 309.69568658968694\n",
      "Time 171 with reward: 340.0633999879057\n",
      "Time 172 with reward: 401.7369631089981\n",
      "Time 173 with reward: 313.59290512396456\n",
      "Time 174 with reward: 295.87658519402646\n",
      "Time 175 with reward: 352.21977403734275\n",
      "Time 176 with reward: 334.667868183111\n",
      "Time 177 with reward: 377.8453628272603\n",
      "Time 178 with reward: 335.5120701181837\n",
      "Time 179 with reward: 347.73298132073245\n",
      "Time 180 with reward: 275.1684776674559\n",
      "Time 181 with reward: 241.7626105587382\n",
      "Time 182 with reward: 268.9571534072222\n",
      "Time 183 with reward: 267.0947561458056\n",
      "Time 184 with reward: 193.53394232486392\n",
      "Time 185 with reward: 270.96894075371404\n",
      "Time 186 with reward: 306.6847401969724\n",
      "Time 187 with reward: 344.31112555127027\n",
      "Time 188 with reward: 308.43706084632265\n",
      "Time 189 with reward: 284.8022394850941\n",
      "Time 190 with reward: 327.9430698469026\n",
      "Time 191 with reward: 285.851204526988\n",
      "Time 192 with reward: 282.79313991523463\n",
      "Time 193 with reward: 301.62877284192524\n",
      "Time 194 with reward: 343.0539468367244\n",
      "Time 195 with reward: 286.9675369139174\n",
      "Time 196 with reward: 315.40092633577683\n",
      "Time 197 with reward: 269.69136249527236\n",
      "Time 198 with reward: 321.6583718429078\n",
      "Time 199 with reward: 342.1091638401061\n",
      "Running experiment 5 for ete\n",
      "Time 130 with reward: 360.88096375263586\n",
      "Time 131 with reward: 345.33877784217054\n",
      "Time 132 with reward: 310.7887892407966\n",
      "Time 133 with reward: 314.62055741486495\n",
      "Time 134 with reward: 353.89876612201124\n",
      "Time 135 with reward: 256.36885006323473\n",
      "Time 136 with reward: 358.2476931208282\n",
      "Time 137 with reward: 293.15165385636664\n",
      "Time 138 with reward: 308.83170548462533\n",
      "Time 139 with reward: 314.4826916970716\n",
      "Time 140 with reward: 286.53560761936694\n",
      "Time 141 with reward: 275.61808014330535\n",
      "Time 142 with reward: 345.2009121243772\n",
      "Time 143 with reward: 345.1666080779525\n",
      "Time 144 with reward: 349.2741076876075\n",
      "Time 145 with reward: 275.480214425512\n",
      "Time 146 with reward: 310.4094961338413\n",
      "Time 147 with reward: 323.5941428480856\n",
      "Time 148 with reward: 249.38665243261005\n",
      "Time 149 with reward: 290.8213219779301\n",
      "Time 150 with reward: 298.1424636843953\n",
      "Time 151 with reward: 314.34482597927826\n",
      "Time 152 with reward: 351.902964986768\n",
      "Time 153 with reward: 336.3651924089499\n",
      "Time 154 with reward: 323.31841141249896\n",
      "Time 155 with reward: 308.41810833124526\n",
      "Time 156 with reward: 340.71411940776693\n",
      "Time 157 with reward: 280.242738577709\n",
      "Time 158 with reward: 250.44213241520177\n",
      "Time 159 with reward: 410.29695138883875\n",
      "Time 160 with reward: 358.1098274030349\n",
      "Time 161 with reward: 364.9541593158662\n",
      "Time 162 with reward: 282.46241205613666\n",
      "Time 163 with reward: 252.79967161142275\n",
      "Time 164 with reward: 295.64705877038097\n",
      "Time 165 with reward: 367.18697450762414\n",
      "Time 166 with reward: 299.99598576919794\n",
      "Time 167 with reward: 323.4562771302923\n",
      "Time 168 with reward: 317.2538280466726\n",
      "Time 169 with reward: 410.4348171066321\n",
      "Time 170 with reward: 305.922703417231\n",
      "Time 171 with reward: 336.6775881268775\n",
      "Time 172 with reward: 406.0858901078151\n",
      "Time 173 with reward: 327.80520412910926\n",
      "Time 174 with reward: 294.8945175411604\n",
      "Time 175 with reward: 317.9146633909616\n",
      "Time 176 with reward: 349.5498391231942\n",
      "Time 177 with reward: 401.7369631089981\n",
      "Time 178 with reward: 340.71411940776693\n",
      "Time 179 with reward: 384.2033893959368\n",
      "Time 180 with reward: 317.1159623288793\n",
      "Time 181 with reward: 239.8818811561511\n",
      "Time 182 with reward: 265.4803012142487\n",
      "Time 183 with reward: 286.6734733371603\n",
      "Time 184 with reward: 327.5294726935226\n",
      "Time 185 with reward: 272.0489016914933\n",
      "Time 186 with reward: 299.54634470738404\n",
      "Time 187 with reward: 317.2538280466726\n",
      "Time 188 with reward: 334.51167032414725\n",
      "Time 189 with reward: 306.0605691350243\n",
      "Time 190 with reward: 352.04524403720853\n",
      "Time 191 with reward: 310.9135132452596\n",
      "Time 192 with reward: 286.81133905495363\n",
      "Time 193 with reward: 291.0224003359773\n",
      "Time 194 with reward: 324.0981599595039\n",
      "Time 195 with reward: 314.7584231326583\n",
      "Time 196 with reward: 351.9073783194152\n",
      "Time 197 with reward: 269.27776534189235\n",
      "Time 198 with reward: 307.7673889113841\n",
      "Time 199 with reward: 338.99846304075754\n",
      "Running experiment 6 for ete\n",
      "Time 130 with reward: 348.83602957903986\n",
      "Time 131 with reward: 360.7437184087495\n",
      "Time 132 with reward: 297.77631229077036\n",
      "Time 133 with reward: 271.78631196923703\n",
      "Time 134 with reward: 349.6877048409876\n",
      "Time 135 with reward: 262.67486081822295\n",
      "Time 136 with reward: 362.6149522608156\n",
      "Time 137 with reward: 284.4537998587327\n",
      "Time 138 with reward: 314.4826916970716\n",
      "Time 139 with reward: 302.674757273996\n",
      "Time 140 with reward: 301.71164213620733\n",
      "Time 141 with reward: 293.0137881385733\n",
      "Time 142 with reward: 350.53128640215334\n",
      "Time 143 with reward: 299.54634470738404\n",
      "Time 144 with reward: 327.80520412910926\n",
      "Time 145 with reward: 262.70916486464773\n",
      "Time 146 with reward: 296.53982595331104\n",
      "Time 147 with reward: 323.6124749892561\n",
      "Time 148 with reward: 238.5350639593991\n",
      "Time 149 with reward: 299.8581200514046\n",
      "Time 150 with reward: 294.1147689941554\n",
      "Time 151 with reward: 314.89628885045164\n",
      "Time 152 with reward: 356.5320367538189\n",
      "Time 153 with reward: 315.034154568245\n",
      "Time 154 with reward: 343.2095243217812\n",
      "Time 155 with reward: 307.61765400246134\n",
      "Time 156 with reward: 349.6877048409876\n",
      "Time 157 with reward: 279.9670071421223\n",
      "Time 158 with reward: 282.60027777393\n",
      "Time 159 with reward: 390.73594596474754\n",
      "Time 160 with reward: 338.8245534145303\n",
      "Time 161 with reward: 336.900683374869\n",
      "Time 162 with reward: 314.7584231326583\n",
      "Time 163 with reward: 270.83107503592066\n",
      "Time 164 with reward: 305.922703417231\n",
      "Time 165 with reward: 345.2009121243772\n",
      "Time 166 with reward: 323.4562771302923\n",
      "Time 167 with reward: 332.2919968457196\n",
      "Time 168 with reward: 319.1073501314753\n",
      "Time 169 with reward: 405.94802439002177\n",
      "Time 170 with reward: 292.2252030009188\n",
      "Time 171 with reward: 358.5234245564149\n",
      "Time 172 with reward: 423.61946382087643\n",
      "Time 173 with reward: 289.28903220170446\n",
      "Time 174 with reward: 319.383081567062\n",
      "Time 175 with reward: 334.51167032414725\n",
      "Time 176 with reward: 353.89876612201124\n",
      "Time 177 with reward: 384.34125511373014\n",
      "Time 178 with reward: 332.2576927992949\n",
      "Time 179 with reward: 341.3691439503089\n",
      "Time 180 with reward: 298.84298909992765\n",
      "Time 181 with reward: 223.9481149822501\n",
      "Time 182 with reward: 269.53578501021553\n",
      "Time 183 with reward: 293.1173498099419\n",
      "Time 184 with reward: 314.7584231326583\n",
      "Time 185 with reward: 297.8667322488086\n",
      "Time 186 with reward: 291.43599748935736\n",
      "Time 187 with reward: 345.33877784217054\n",
      "Time 188 with reward: 325.9516820443066\n",
      "Time 189 with reward: 301.71164213620733\n",
      "Time 190 with reward: 360.6052323170492\n",
      "Time 191 with reward: 293.286846103522\n",
      "Time 192 with reward: 297.50058085518367\n",
      "Time 193 with reward: 295.3713273347943\n",
      "Time 194 with reward: 344.41232698672275\n",
      "Time 195 with reward: 310.28996255721836\n",
      "Time 196 with reward: 358.2476931208282\n",
      "Time 197 with reward: 284.69522724789465\n",
      "Time 198 with reward: 362.4587544018519\n",
      "Time 199 with reward: 358.403890979792\n",
      "Running experiment 7 for ete\n",
      "Time 130 with reward: 358.1098274030349\n",
      "Time 131 with reward: 327.1653435235436\n",
      "Time 132 with reward: 305.2719839973698\n",
      "Time 133 with reward: 287.7771419693747\n",
      "Time 134 with reward: 341.97129812231276\n",
      "Time 135 with reward: 260.5621995769949\n",
      "Time 136 with reward: 346.4764229800935\n",
      "Time 137 with reward: 269.69136249527236\n",
      "Time 138 with reward: 323.5941428480856\n",
      "Time 139 with reward: 306.35463271178145\n",
      "Time 140 with reward: 266.4617484932079\n",
      "Time 141 with reward: 275.79261014343956\n",
      "Time 142 with reward: 317.39169376446597\n",
      "Time 143 with reward: 306.09723341736515\n",
      "Time 144 with reward: 336.40185669129073\n",
      "Time 145 with reward: 266.30555063424407\n",
      "Time 146 with reward: 288.06851776949946\n",
      "Time 147 with reward: 332.4665268458538\n",
      "Time 148 with reward: 256.0570747192141\n",
      "Time 149 with reward: 300.0143179103684\n",
      "Time 150 with reward: 307.04201641398345\n",
      "Time 151 with reward: 319.1073501314753\n",
      "Time 152 with reward: 352.18310975500185\n",
      "Time 153 with reward: 317.39169376446597\n",
      "Time 154 with reward: 334.4756264157133\n",
      "Time 155 with reward: 312.80431998631\n",
      "Time 156 with reward: 340.85198512556025\n",
      "Time 157 with reward: 253.43329963792735\n",
      "Time 158 with reward: 267.1959575812581\n",
      "Time 159 with reward: 373.5147679696138\n",
      "Time 160 with reward: 349.4119734054009\n",
      "Time 161 with reward: 373.63430154623666\n",
      "Time 162 with reward: 340.4383879721802\n",
      "Time 163 with reward: 249.37781584196057\n",
      "Time 164 with reward: 332.8598469712987\n",
      "Time 165 with reward: 375.680065398437\n",
      "Time 166 with reward: 317.9051678404407\n",
      "Time 167 with reward: 323.4562771302923\n",
      "Time 168 with reward: 326.77755183820886\n",
      "Time 169 with reward: 406.0858901078151\n",
      "Time 170 with reward: 325.40083954704016\n",
      "Time 171 with reward: 353.1285131255271\n",
      "Time 172 with reward: 410.3702799535205\n",
      "Time 173 with reward: 306.4096291352927\n",
      "Time 174 with reward: 323.6858035539377\n",
      "Time 175 with reward: 348.52218683229387\n",
      "Time 176 with reward: 367.08341283625555\n",
      "Time 177 with reward: 397.38803611018113\n",
      "Time 178 with reward: 343.1918125545177\n",
      "Time 179 with reward: 366.80768140066886\n",
      "Time 180 with reward: 336.2273266911566\n",
      "Time 181 with reward: 233.36765672851087\n",
      "Time 182 with reward: 263.0032284414048\n",
      "Time 183 with reward: 277.9395754310924\n",
      "Time 184 with reward: 301.987373571794\n",
      "Time 185 with reward: 280.98103729213057\n",
      "Time 186 with reward: 281.4170479979728\n",
      "Time 187 with reward: 369.9544261084513\n",
      "Time 188 with reward: 328.0992677058664\n",
      "Time 189 with reward: 308.12466512839507\n",
      "Time 190 with reward: 350.8274173816359\n",
      "Time 191 with reward: 298.4820281341428\n",
      "Time 192 with reward: 294.27096685311915\n",
      "Time 193 with reward: 309.65695490462065\n",
      "Time 194 with reward: 362.4587544018519\n",
      "Time 195 with reward: 299.8581200514046\n",
      "Time 196 with reward: 329.3924903288461\n",
      "Time 197 with reward: 265.204569778662\n",
      "Time 198 with reward: 329.2369128437893\n",
      "Time 199 with reward: 340.87031726673064\n",
      "Running experiment 8 for ete\n",
      "Time 130 with reward: 339.9255342701124\n",
      "Time 131 with reward: 367.1567414009373\n",
      "Time 132 with reward: 303.16168299205776\n",
      "Time 133 with reward: 274.6916292878575\n",
      "Time 134 with reward: 333.19057483039666\n",
      "Time 135 with reward: 249.45998099729178\n",
      "Time 136 with reward: 345.35710998334105\n",
      "Time 137 with reward: 295.3536155675308\n",
      "Time 138 with reward: 327.66733841131594\n",
      "Time 139 with reward: 336.40185669129073\n",
      "Time 140 with reward: 277.0497888579854\n",
      "Time 141 with reward: 284.4537998587327\n",
      "Time 142 with reward: 345.2009121243772\n",
      "Time 143 with reward: 322.0978969802939\n",
      "Time 144 with reward: 320.36452884602113\n",
      "Time 145 with reward: 273.902423776296\n",
      "Time 146 with reward: 283.5090168621144\n",
      "Time 147 with reward: 347.12714239995466\n",
      "Time 148 with reward: 232.49558192266733\n",
      "Time 149 with reward: 285.1146352030217\n",
      "Time 150 with reward: 310.54736185163466\n",
      "Time 151 with reward: 280.4533124862771\n",
      "Time 152 with reward: 360.43132269082196\n",
      "Time 153 with reward: 317.9784964051224\n",
      "Time 154 with reward: 340.85198512556025\n",
      "Time 155 with reward: 323.8047167566537\n",
      "Time 156 with reward: 356.1557242566866\n",
      "Time 157 with reward: 270.10363513579466\n",
      "Time 158 with reward: 264.7732608580185\n",
      "Time 159 with reward: 382.7634644645142\n",
      "Time 160 with reward: 334.51167032414725\n",
      "Time 161 with reward: 375.50553539830287\n",
      "Time 162 with reward: 307.45561356736346\n",
      "Time 163 with reward: 266.01210743139393\n",
      "Time 164 with reward: 272.22611946825987\n",
      "Time 165 with reward: 358.14649168537574\n",
      "Time 166 with reward: 323.4562771302923\n",
      "Time 167 with reward: 308.7121719080024\n",
      "Time 168 with reward: 332.2919968457196\n",
      "Time 169 with reward: 414.8020762466195\n",
      "Time 170 with reward: 282.34349885342067\n",
      "Time 171 with reward: 343.38467469582235\n",
      "Time 172 with reward: 389.9656929682634\n",
      "Time 173 with reward: 286.81133905495363\n",
      "Time 174 with reward: 304.48277848580835\n",
      "Time 175 with reward: 308.55597404903864\n",
      "Time 176 with reward: 349.4119734054009\n",
      "Time 177 with reward: 372.55165283182504\n",
      "Time 178 with reward: 324.75012012717895\n",
      "Time 179 with reward: 347.8341827561849\n",
      "Time 180 with reward: 300.8401877042707\n",
      "Time 181 with reward: 226.9729658774935\n",
      "Time 182 with reward: 274.7099614290279\n",
      "Time 183 with reward: 263.8651421437411\n",
      "Time 184 with reward: 263.40604411737064\n",
      "Time 185 with reward: 280.27436915349574\n",
      "Time 186 with reward: 309.38184384294095\n",
      "Time 187 with reward: 342.1274959812765\n",
      "Time 188 with reward: 331.28474409871507\n",
      "Time 189 with reward: 288.7015254220972\n",
      "Time 190 with reward: 342.2786601336861\n",
      "Time 191 with reward: 294.2526347119487\n",
      "Time 192 with reward: 297.3627151373903\n",
      "Time 193 with reward: 276.14104976980104\n",
      "Time 194 with reward: 338.86121769687117\n",
      "Time 195 with reward: 307.29941570839975\n",
      "Time 196 with reward: 357.97196168524147\n",
      "Time 197 with reward: 271.2691531444883\n",
      "Time 198 with reward: 328.0163984115843\n",
      "Time 199 with reward: 345.2009121243772\n",
      "Running experiment 9 for ete\n",
      "Time 130 with reward: 368.99131097066254\n",
      "Time 131 with reward: 335.4754058358429\n",
      "Time 132 with reward: 321.0335804070527\n",
      "Time 133 with reward: 273.90304415020296\n",
      "Time 134 with reward: 330.06216226378467\n",
      "Time 135 with reward: 260.7937934033657\n",
      "Time 136 with reward: 325.92442954744274\n",
      "Time 137 with reward: 264.03967214387524\n",
      "Time 138 with reward: 296.4729285642833\n",
      "Time 139 with reward: 307.1615499906063\n",
      "Time 140 with reward: 261.8862756805685\n",
      "Time 141 with reward: 277.9762397134333\n",
      "Time 142 with reward: 331.2643445548192\n",
      "Time 143 with reward: 291.2987521454709\n",
      "Time 144 with reward: 362.4587544018519\n",
      "Time 145 with reward: 249.71738029170803\n",
      "Time 146 with reward: 291.05968499222513\n",
      "Time 147 with reward: 294.24309398234834\n",
      "Time 148 with reward: 233.57885101098591\n",
      "Time 149 with reward: 297.7117751376587\n",
      "Time 150 with reward: 291.00468856871385\n",
      "Time 151 with reward: 286.94982514665395\n",
      "Time 152 with reward: 340.01719497596446\n",
      "Time 153 with reward: 319.26354799043906\n",
      "Time 154 with reward: 332.05292969247375\n",
      "Time 155 with reward: 295.3902798498716\n",
      "Time 156 with reward: 322.4652891217327\n",
      "Time 157 with reward: 291.93113942416164\n",
      "Time 158 with reward: 239.95520972083284\n",
      "Time 159 with reward: 349.81602982918054\n",
      "Time 160 with reward: 333.4113098424721\n",
      "Time 161 with reward: 371.2944741172792\n",
      "Time 162 with reward: 301.784970700889\n",
      "Time 163 with reward: 267.35451567613796\n",
      "Time 164 with reward: 314.53768812058286\n",
      "Time 165 with reward: 342.0996231105057\n",
      "Time 166 with reward: 307.1982142729472\n",
      "Time 167 with reward: 288.9955889988543\n",
      "Time 168 with reward: 304.0052645532236\n",
      "Time 169 with reward: 401.8286238148503\n",
      "Time 170 with reward: 291.9494715653321\n",
      "Time 171 with reward: 326.98874612068397\n",
      "Time 172 with reward: 400.8288443947207\n",
      "Time 173 with reward: 298.51869241648365\n",
      "Time 174 with reward: 295.5648098500059\n",
      "Time 175 with reward: 332.07126183364414\n",
      "Time 176 with reward: 336.71425240921826\n",
      "Time 177 with reward: 386.5432168248943\n",
      "Time 178 with reward: 347.40287383554136\n",
      "Time 179 with reward: 354.00875896903375\n",
      "Time 180 with reward: 300.95972128089363\n",
      "Time 181 with reward: 262.70916486464773\n",
      "Time 182 with reward: 262.16200711615517\n",
      "Time 183 with reward: 247.9680402521809\n",
      "Time 184 with reward: 285.9221728557536\n",
      "Time 185 with reward: 268.3007136102488\n",
      "Time 186 with reward: 294.16976541766667\n",
      "Time 187 with reward: 327.7406669759976\n",
      "Time 188 with reward: 303.0788136977757\n",
      "Time 189 with reward: 262.8191577116703\n",
      "Time 190 with reward: 315.00628169747415\n",
      "Time 191 with reward: 283.28828185003897\n",
      "Time 192 with reward: 263.782272849459\n",
      "Time 193 with reward: 299.7208747075182\n",
      "Time 194 with reward: 329.4600080917808\n",
      "Time 195 with reward: 284.38926270562104\n",
      "Time 196 with reward: 297.8238353874067\n",
      "Time 197 with reward: 247.60707928639604\n",
      "Time 198 with reward: 302.76641797984814\n",
      "Time 199 with reward: 353.89876612201124\n",
      "Running experiment 10 for ete\n",
      "Time 130 with reward: 364.303439896005\n",
      "Time 131 with reward: 348.97182789410783\n",
      "Time 132 with reward: 319.383081567062\n",
      "Time 133 with reward: 270.37936657138135\n",
      "Time 134 with reward: 323.5941428480856\n",
      "Time 135 with reward: 272.09440256448374\n",
      "Time 136 with reward: 337.2828066737482\n",
      "Time 137 with reward: 272.75523790877276\n",
      "Time 138 with reward: 327.5294726935226\n",
      "Time 139 with reward: 291.9494715653321\n",
      "Time 140 with reward: 280.1048728599157\n",
      "Time 141 with reward: 273.7468462912392\n",
      "Time 142 with reward: 336.6725544203233\n",
      "Time 143 with reward: 302.0607021364757\n",
      "Time 144 with reward: 343.1918125545177\n",
      "Time 145 with reward: 247.65328429833727\n",
      "Time 146 with reward: 293.1699859975371\n",
      "Time 147 with reward: 336.3651924089499\n",
      "Time 148 with reward: 240.83615970329035\n",
      "Time 149 with reward: 303.57465977153083\n",
      "Time 150 with reward: 306.1984348528176\n",
      "Time 151 with reward: 300.15218362816177\n",
      "Time 152 with reward: 358.2476931208282\n",
      "Time 153 with reward: 304.0514695651648\n",
      "Time 154 with reward: 335.5766072712954\n",
      "Time 155 with reward: 310.6200700424094\n",
      "Time 156 with reward: 330.14503155806676\n",
      "Time 157 with reward: 295.50919305258765\n",
      "Time 158 with reward: 245.19392329275684\n",
      "Time 159 with reward: 371.36780268196094\n",
      "Time 160 with reward: 353.76090040421786\n",
      "Time 161 with reward: 379.85446239711985\n",
      "Time 162 with reward: 318.0430335582341\n",
      "Time 163 with reward: 260.1397658329653\n",
      "Time 164 with reward: 319.383081567062\n",
      "Time 165 with reward: 361.41276996978104\n",
      "Time 166 with reward: 300.1338514869914\n",
      "Time 167 with reward: 332.15413112792623\n",
      "Time 168 with reward: 318.3554292761616\n",
      "Time 169 with reward: 414.7837441054491\n",
      "Time 170 with reward: 302.1252392895874\n",
      "Time 171 with reward: 345.23254270016395\n",
      "Time 172 with reward: 389.8461593916405\n",
      "Time 173 with reward: 316.0289002818204\n",
      "Time 174 with reward: 306.3862632875681\n",
      "Time 175 with reward: 352.18310975500185\n",
      "Time 176 with reward: 362.4587544018519\n",
      "Time 177 with reward: 378.92801154167194\n",
      "Time 178 with reward: 349.56817126436465\n",
      "Time 179 with reward: 375.6434011160962\n",
      "Time 180 with reward: 310.7218918517688\n",
      "Time 181 with reward: 231.34022501748092\n",
      "Time 182 with reward: 263.62677912944605\n",
      "Time 183 with reward: 266.4977924016418\n",
      "Time 184 with reward: 316.9603848438224\n",
      "Time 185 with reward: 278.38921649290637\n",
      "Time 186 with reward: 292.43846468611923\n",
      "Time 187 with reward: 346.5959565567164\n",
      "Time 188 with reward: 332.15413112792623\n",
      "Time 189 with reward: 308.55597404903864\n",
      "Time 190 with reward: 345.33877784217054\n",
      "Time 191 with reward: 293.0137881385733\n",
      "Time 192 with reward: 282.15063671211607\n",
      "Time 193 with reward: 292.1056694242959\n",
      "Time 194 with reward: 358.1098274030349\n",
      "Time 195 with reward: 314.7584231326583\n",
      "Time 196 with reward: 353.89876612201124\n",
      "Time 197 with reward: 260.4243338592015\n",
      "Time 198 with reward: 312.73099142162835\n",
      "Time 199 with reward: 347.4212059767118\n"
     ]
    }
   ],
   "source": [
    "Y_t_exp_times = []\n",
    "# Run the experiment 10 times\n",
    "for times in range(10):\n",
    "    print(f\"Running experiment {times + 1} for ete\")\n",
    "\n",
    "    Y_t_exp = exploration_then_exploitation(130)\n",
    "\n",
    "    # Append the results of this experiment\n",
    "    Y_t_exp_times.append(Y_t_exp)\n",
    "    \n",
    "\n",
    "# Convert lists to NumPy arrays for easier computation\n",
    "Y_t_exp_times = np.array(Y_t_exp_times)\n",
    "# Save the results to .npy files\n",
    "np.save(f'Y_t_exp_time-ete-under-interference-n20-k14-d120-s10_10times.npy', Y_t_exp_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32994398-9013-4cdd-af7b-97ca3eff8f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
